# python audit.py /Users/jar/otrepo/files.opentreeoflife.org /Users/jar question: varela:/home/opentree/files.opentreeoflife.org/

artifact_list_path = 'artifact_list.json'

import argparse
p = argparse.ArgumentParser()
p.add_argument("repo", help="root of local files.opentreeoflife.org repo checkout, e.g. '/Users/jar/otrepo/files.opentreeoflife.org'")
p.add_argument("base", help="base directory for local paths, e.g. '/Users/jar'")
p.add_argument("prefix", help="prefix that says a path is relative to base, e.g. 'question:'")
p.add_argument("files", help="location base for files host, e.g. 'http://files.opentreeoflife.org/' or 'varela:/home/opentree/files.opentreeoflife.org/'")

# os.path.realpath(symlink)

# Value of "legal" field:
#   OK to redistribute:
#     pd = public domain because US govt or out of copyright
#     cc0 = cc0
#     public = distributed to public on web without click-through license
#   anything else = license terms require something, do not redistribute:
#     handoff = received privately without nondisclosure or license
#     cc-by-v3.0 = copying requires attribution
#     $ = access requires payment, etc.

# sources/    - files that open tree has copied from elsewhere
#   series/
#     versionfile
#     versiondir/
#       file1
#       file2
# targets/    - files generated by open tree
#   series/
#     versionfile
#     versiondir/
#       file1
#       file2

import json, os

# load and validate

allowed_keys = ["name", "retrieved_from", "source_suffix", "target_suffix", "legal", "==="]
series_allowed_keys = allowed_keys + ["versions", "idspace"]
version_allowed_keys = allowed_keys + ["source", "target"]

# Do validation up front
# Also, copy some fields (inheritance)

def load(artifact_list_path):
    with open(artifact_list_path) as infile:
        directory = json.load(infile)
        for s in directory["series"]:
            for key in s:
                if not key in series_allowed_keys:
                    print 'echo @@ invalid series field', key
            if "name" in s:
                sname = s["name"]
            else:
                print 'echo @@ series has no name', s
                continue
            for v in s["versions"]:
                for key in v:
                    if not key in version_allowed_keys:
                        print 'echo @@ unrecognized key in version', key
                # Inheritance!
                for key in s:
                    if key in allowed_keys and not key in v:
                        v[key] = s[key]
                # default version location is files.opentreeoflife.org/series/version/
                #  which contains artifact files (zips, tarballs)
                if not 'name' in v:
                    print 'echo @@ artifact has no name', v
                    continue
                vname = v["name"]
                v['series_name'] = sname
                def check_artifact(artifact_field, suffix_field, legal):
                    artifact = v.get(artifact_field)
                    if artifact == None:
                        return None
                    suffix = v.get(suffix_field)
                    if "locations" in artifact or "bytes" in artifact:
                        if suffix == None:
                            print 'echo @@ missing suffix', vname
                        else:
                            if legal != None:
                                artifact['suffix'] = suffix
                                artifact["legal"] = legal
                                if legal in ["pd", "cc0", "public"]:
                                    return suffix
                                else:
                                    print 'echo @@ not known to be public', vname, suffix
                            else:
                                print 'echo @@ missing legal', vname, suffix
                    return None
                s1 = check_artifact("source", "source_suffix", v["legal"])
                s2 = check_artifact("target", "target_suffix", "cc0")
                if s1 != None:
                    if s2 != None:
                        if s1 == s2:
                            print 'echo @@ suffix clash', suffix, a_suffix, vname
                elif s2 == None:
                    print 'echo @@ no archivable artifacts', vname
                #if "target" in v and "source" in v:
                #    v["target"]["derived_from"] = ... ? ...
        return directory

# shuffle bits around to get local artifact store into shape

def audit(artifact_list_path, repo, prefix, local, files_prefix):
    directory = load(artifact_list_path)
    print 'set -e'
    def doit():
        for s in directory["series"]:
            for v in s["versions"]:
                vname = v["name"]
                path = os.path.join(v['series_name'], vname)
                artifacts = []
                def add(artifact_field):
                    artifact = v.get(artifact_field)
                    if artifact != None:
                        if "locations" in artifact or "bytes" in artifact:
                            if artifact["legal"] in ["pd", "cc0", "public"]:
                                suffix = artifact['suffix']
                                fullname = os.path.join(path, vname + suffix)
                                artifacts.append((fullname, artifact, v))
                add("target")
                add("source")
                for a in artifacts:
                    balance(*a)

    # fullname is relative to local repo clone.
    # exportp says whether it should go on the files server at all.

    def balance(fullname, artifact, v):

        vname = v["name"]

        def local_path(loc):
            path = None
            if not ':' in loc:
                # elsewhere in repo
                return os.path.join(repo, loc)
            elif loc.startswith(prefix):
                # somewhere else on this machine
                return os.path.join(local, loc[len(prefix):])
            else:
                # on the interwebs
                return None

        locations = artifact.get("locations")
        dst = os.path.join(repo, fullname)
        if os.path.exists(dst) and not os.path.islink(dst):
            # print 'echo %s already exists, will not overwrite.' % (dst)
            for loc in locations:
                path = local_path(loc)
                if path != None:
                    if os.path.exists(path):
                        if path == dst:
                            True
                        elif os.path.islink(path) or os.path.isdir(path):
                            # Is a symlink or directory - this is the desired state
                            True
                        else:
                            print "echo @@ local path is file or directory, not link:", path
                            print "echo ... for", dst, "which is OK"
                    else:
                        print "echo @@ no such local file or directory:", path
                        print "echo ... for", dst, "which is OK"
            return
        print 'echo --- %s ---' % vname
        if locations == None:
            print 'echo @@ no locations for this artifact', artifact["name"]
            return
        if len(locations) == 0:
            return
        tbd = None
        local_tbd = None
        for loc in locations: # potential origins
            path = local_path(loc)
            tbd = None
            if path != None:
                if os.path.exists(path):
                    if path == dst:
                        # success (should have been caught earlier)
                        tbd = "echo already have %s !" % (path)
                    elif path.endswith('/') and dst.endswith('.tgz'):
                        dir = path[0:-1]
                        # create tarball, contents = files in path
                        tbd = "./make-tarball %s %s" % (dir, dst)
                    else:
                        # move file and leave symbolic link behind.
                        if not dst.startswith('/'):
                            print 'echo @@ relative links probably will not work!', dst
                        tbd = "mv %s %s && ln -sf %s %s" % (path, dst, dst, path)
                else:
                    if ':' in loc:
                        print "echo @@ no such file", path
                        loc = ""
                    else:
                        print "echo @@ no such file", path
                        print "echo @@  ... might be on files.opentreeoflife.org"
                        loc = files_prefix + loc
            if tbd != None:
                local_tbd = tbd
            else:
                # somewhere on the interwebs
                if '://' in loc:
                    # print 'curl -s -I "%s" | (if ! grep -q 200.OK; then echo Not found: "%s"; fi)' % (loc, loc)
                    tbd = 'curl -s "%s" >%s.tmp && mv %s.tmp %s' % (loc, dst, dst, dst)
                elif ':' in loc:
                    # print "if ! ssh %s test -r %s; then echo Not found: %s; fi" % (loc[0:i], loc[i+1:], loc)
                    if prefix != 'files:':
                        tbd = "scp -p %s %s" % (loc, dst)
                    else:
                        p = os.path.join(v["series_name"], os.path.basename(dst))
                        tbd = 'echo on-question-scp %s files:files.opentreeoflife.org/%s' % (p, p)
        dir = os.path.dirname(dst)
        if local_tbd != None:
            if not os.path.isdir(dir):
                print "mkdir -p %s" % dir
            print local_tbd
        elif tbd != None:
            if not os.path.isdir(dir):
                print "mkdir -p %s" % dir
            print tbd
        else:
            print "echo @@ cannot find", ' or '.join(locations)
    doit()

args = p.parse_args()

audit(artifact_list_path, args.repo, args.prefix, args.base, args.files)
